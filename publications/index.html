<!doctype html><html lang><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>| AITR</title><meta name=description content="AITR is a research lab working on deveoping applying foundational AI and machine learning methods to solve real-world problems across domains such as document analysis, computer vision, and medical imaging. "><meta name=author content="AITR"><meta property="og:title" content><meta property="og:description" content="Publications We are interested in building resource efficient intelligent systems, mainly performing intelligent tasks on image data such as medical imaging or video recordings. Here are some of the projects we&rsquo;ve been working on.
Medical Image Analysis and Diagnostic Assistance We work on image data such as X-Ray, CT, Electron Microscopy as well as Dermoscopic images. Our efforts are to create diagnostic assistive tools using computer visions methods that can analyze above types of images so that an informative judgement can be made by medical practitioners using the output of such methods."><meta property="og:type" content="article"><meta property="og:url" content="https://aitr-lab.github.io/publications/"><meta property="article:section" content><link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css integrity=sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2 crossorigin=anonymous><link rel=stylesheet href=/sass/researcher.min.css><link rel=stylesheet href=/style/main.min.css><link rel=stylesheet href=/css/publications.min.css><style>.navbar-brand.title{font-size:1.7rem!important}</style><link rel=icon type=image/ico href=https://aitr-lab.github.io/favicon.ico><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","url":"https://chicagohai.github.io","logo":"https://chicagohai.github.io/avatar.jpg"}</script></head><body><div class="container mt-5"><nav class="navbar navbar-expand-sm flex-column flex-sm-row text-nowrap p-0"><a id=header__title class="navbar-brand mx-0 mr-sm-auto title" href=https://aitr-lab.github.io/>Artificial Intelligence Translational Research Lab<span id=header__title_abbr>&nbsp;<wbr>(AITR)</span></a><div class="navbar-nav flex-row flex-wrap justify-content-center"><a class="nav-item nav-link" href=/people>People</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/news>News</a>
<span class="nav-item navbar-text mx-1">/</span>
<a class="nav-item nav-link" href=/publications>Publications</a></div></nav></div><hr><div id=content><div class=container><h1></h1><h1 id=publications>Publications</h1><p>We are interested in building resource efficient intelligent systems, mainly performing intelligent tasks on image data such as medical imaging or video recordings. Here are some of the projects we&rsquo;ve been working on.</p><h2 id=medical-image-analysis-and-diagnostic-assistance>Medical Image Analysis and Diagnostic Assistance</h2><div class=description-block>We work on image data such as X-Ray, CT, Electron Microscopy as well as Dermoscopic images. Our efforts are to create diagnostic assistive tools using computer visions methods that can analyze above types of images so that an informative judgement can be made by medical practitioners using the output of such methods. Following are some of our publications in this area</div><ul><li>Amarasinghe, N. H., & Ambegoda, T. D. (2024). <a href=/assets/publications/few-shot-lung-cancer-classification-using-prototypical-networkspdf.pdf target=_blank>Few-Shot Lung Cancer Classification Using Prototypical Networks</a>. In <em>2024 4th International Conference on Advanced Research in Computing (ICARC)</em> (pp. 79-84). IEEE.</li><li>Nimalsiri, W., Hennayake, M., Rathnayake, K., Ambegoda, T. D., & Meedeniya, D. (2023). <a href=/assets/publications/automated-radiology-report-generation-using-transformerspdf.pdf target=_blank>Automated radiology report generation using transformers</a>. In <em>2023 3rd International Conference on Advanced Research in Computing (ICARC)</em> (pp. 90-95). IEEE.</li><li>Nimalsiri, W., Hennayake, M., Rathnayake, K., Ambegoda, T. D., & Meedeniya, D. (2023). <a href=/assets/publications/cxlseg-dataset-chest-x-ray-with-lung-segmentationpdf.pdf target=_blank>Cxlseg dataset: Chest x-ray with lung segmentation</a>. In <em>2023 International Conference On Cyber Management And Engineering (CyMaEn)</em> (pp. 327-331). IEEE.</li><li>Dasanayaka, S., Shantha, V., Silva, S., Meedeniya, D., & Ambegoda, T. (2022). <a href=/assets/publications/interpretable-machine-learning-for-brain-tumour-analysis-using-mri-and-whole-slide-imagespdf.pdf target=_blank>Interpretable machine learning for brain tumour analysis using MRI and whole slide images</a>. <em>Software Impacts</em>, 13, 100340.</li><li>Wijerathna, V., Raveen, H., Abeygunawardhana, S., & Ambegoda, T. D. (2022). <a href=/assets/publications/chest-x-ray-caption-generation-with-chexnetpdf.pdf target=_blank>Chest x-ray caption generation with chexnet</a>. In <em>2022 Moratuwa Engineering Research Conference (MERCon)</em> (pp. 1-6). IEEE.</li><li>Silva, K., Maheepala, T., Tharaka, K., & Ambegoda, T. D. (2022). <a href=/assets/publications/adversarial-learning-to-improve-question-image-embedding-in-medical-visual-question-answeringpdf.pdf target=_blank>Adversarial Learning to Improve Question Image Embedding in Medical Visual Question Answering</a>. In <em>2022 Moratuwa Engineering Research Conference (MERCon)</em> (pp. 1-6). IEEE.</li><li>Dasanayaka, S., Silva, S., Shantha, V., Meedeniya, D., & Ambegoda, T. (2022). <a href=/assets/publications/interpretable-machine-learning-for-brain-tumor-analysis-using-mri-pdf.pdf target=_blank>Interpretable machine learning for brain tumor analysis using MRI</a>. In <em>2022 2nd International Conference on Advanced Research in Computing (ICARC)</em> (pp. 212-217). IEEE.</li><li>Hussaindeen, A., Iqbal, S., & Ambegoda, T. D. (2022). <a href=/assets/publications/multi-label-prototype-based-interpretable-machine-learning-for-melanoma-detection-pdf.pdf target=_blank>Multi-label prototype based interpretable machine learning for melanoma detection</a>. <em>International Journal Of Advances In Signal And Image Sciences</em>, 8(1), 40-53.</li></ul><h2 id=satellite-image-analysis--remote-sensing>Satellite Image Analysis / Remote Sensing</h2><div class=description-block>In our research on satellite image analysis using computer vision, we explore Mars's surface to better understand its geology and potential for past life. One project involves segmenting serpentine zones on Mars, which helps in studying the planet's geological history. Another focuses on automatically detecting and segmenting non-inverted channels from satellite data, shedding light on Mars's ancient water flow. These efforts aim to provide insights into Mars's environment and support future exploration</div><ul><li>Malaviarachchi, S. P. K., Dharmapriya, P., Chandrajith, R., Pitawala, H. M. T. G. A., Karunatillake, S., Hughes, E., Vithanage, M., Edussuriya, T., Ambegoda, T., Anandakiththi, K., & others. (2024). <a href=/assets/publications/overview-of-sri-lankas-rare-occurrence-of-serpentinites-within-proterozoic-high-grade-metamorphic-basement-rocks-as-a-mars-context-research-sitepdf.pdf target=_blank>Overview of Sri Lanka&rsquo;s Rare Occurrence of Serpentinites Within Proterozoic High-Grade Metamorphic Basement Rocks as a Mars-Context Research Site</a>. <em>LPI Contributions</em>, 3040, 2324.</li><li>Kavinda, K. P. G., Rathnayaka, C. B., Silva, W. G. C., Ambegoda, T. D., Manogaran, R., & Karunatillake, S. (2023). <a href=/assets/publications/resist-tool-to-automatically-segment-martian-inverted-channels-in-hirise-imagespdf.pdf target=_blank>RESIST: Tool to Automatically Segment Martian Inverted Channels in HiRISE Images</a>. In <em>54th Lunar and Planetary Science Conference</em> (Vol. 2806, pp. 1821).</li><li>Jayakody, D. R., Ambegoda, T. D., Karunatillake, S., & Hughes, E. B. (2023). <a href=/assets/publications/optimized-field-sampling-of-mars-analog-serpentine-zones-via-machine-learningpdf.pdf target=_blank>Optimized Field Sampling of Mars-Analog Serpentine Zones via Machine Learning</a>. In <em>54th Lunar and Planetary Science Conference</em> (Vol. 2806, pp. 2242).</li><li>Jayakody, D., & Ambegoda, T. (2023). <a href=/assets/publications/few-shot-multispectral-segmentation-with-representations-generated-by-reinforcement-learningpdf.pdf target=_blank>Few-shot Multispectral Segmentation with Representations Generated by Reinforcement Learning</a>. <em>arXiv preprint arXiv:2311.11827</em>.</li><li>Rathnayaka, C., Silva, G., Pathirana, K., Ambegoda, T., Manogaran, R., & Karunatillake, S. (2023). <a href=/assets/publications/resist-resource-efficient-satellite-image-segmentation-tool-for-curvilinear-structure-segmentation-pdf.pdf target=_blank>RESIST: Resource Efficient Satellite Image Segmentation Tool for Curvilinear Structure Segmentation</a>. In <em>2023 IEEE International Conference on Image Processing (ICIP)</em>.</li><li>Jayakody, N., Cooray, P., Dasanayake, S., & Ambegoda, T. (2023). <a href=/assets/publications/monocular-depth-estimation-of-planetary-landforms-a-diffusion-model-approach-for-faster-inference-pdf.pdf target=_blank>Monocular Depth Estimation of Planetary Landforms: A Diffusion Model Approach for Faster Inference</a>. In <em>2023 IEEE International Conference on Image Processing (ICIP)</em>.</li></ul><h2 id=sensors-and-data-science>Sensors and Data Science</h2><div class=description-block>There are a variety of sensors to capture events in the environment including machines and humans. These could be IMU sensors to detect acceleration, lidar sensors to sense the 3D environment and its changes, wifi transceivers that can capture certain changes in the environment, and vibration sensors that can capture subtle changes in machine vibrations when they are in operation . Our efforts are to develop and apply data science techniques to extract rich features and use them to build tools to support decision making for humans as well as autonomous agents such as robots</div><ul><li>Schmidt, T., Ambegoda, T., & Gunasekera, K. (2023). <a href=/assets/publications/vehicle-classifcation-using-raspberry-pi-a-guide-to-capturing-wifi-csi-datapdf.pdf target=_blank>Vehicle Classification Using Raspberry Pi: A Guide to Capturing WiFi CSI Data</a>. In <em>2023 Moratuwa Engineering Research Conference (MERCon)</em> (pp. 702-707). IEEE.</li><li>Wijesinghe, A., Ambegoda, T. D., Perera, A. S., & Sivakumar, T. (2023). <a href=/assets/publications/siamese-networks-for-rf-based-vehicle-trajectory-predictionpdf.pdf target=_blank>Siamese networks for RF-based vehicle trajectory prediction</a>. In <em>2023 IEEE 17th International Conference on Industrial and Information Systems (ICIIS)</em> (pp. 495-500). IEEE.</li></ul><h2 id=sign-language-recognition>Sign Language Recognition</h2><div class=description-block>Our aim is to build an automatic realtime sign language recognition system for the Sinhala Sign Language that's used in Sri Lanka. We have developed tools to recognize the Sinhala Sign Alphabet as well as a number of words. Currently we are trying to expand the vocabulary as well as the capability to translate sentences in Sinhala Sign Language in realtime. We have already contributed the largest dataset for this purpose and currently working on expanding it further to support similar research and development efforts.</div><ul><li>Sarveswarasarma, P., Sathulakjan, T., Godfrey, V. J. V., & Ambegoda, T. D. (2024). <a href=/assets/publications/air-signing-and-privacy-preserving-signature-verification-for-digital-documentspdf.pdf target=_blank>Air Signing and Privacy-Preserving Signature Verification for Digital Documents</a>. <em>arXiv preprint arXiv:2405.10868</em>.</li><li>Charuka, K., Wickramanayake, S., Ambegoda, T. D., Madhushan, P., & Wijesooriya, D. (2023). <a href=/assets/publications/sign-language-recognition-for-low-resource-languages-using-few-shot-learningpdf.pdf target=_blank>Sign Language Recognition for Low Resource Languages Using Few Shot Learning</a>. In <em>International Conference on Neural Information Processing</em> (pp. 203-214). Springer.</li><li>Weerasooriya, A. A., & Ambegoda, T. D. (2022). <a href=/assets/publications/sinhala-fingerspelling-sign-language-recognition-with-computer-vision-pdf.pdf target=_blank>Sinhala fingerspelling sign language recognition with computer vision</a>. In <em>2022 Moratuwa Engineering Research Conference (MERCon)</em> (pp. 1-6). IEEE.</li></ul><h2 id=smart-agriculture>Smart Agriculture</h2><div class=description-block>IoT and ML methods have a significant scope to make crop monitoring efficient and effective. We have been working on developing cost effective tools and frameworks to monitor the environment of crops and their growth rate with sensor networks and computer vision methods.</div><ul><li>Senevirathne, I., Ambegoda, T., Wijesena, R., & Perera, I. (2022). <a href=/assets/publications/iot-based-soil-nutrient-analyser-using-gaussian-process-regressionpdf.pdf target=_blank>IoT-based soil nutrient analyser using Gaussian process regression</a>. In <em>2022 2nd International Conference on Advanced Research in Computing (ICARC)</em> (pp. 7-12). IEEE.</li></ul><h2 id=robotics-and-iot-with-ai>Robotics and IoT with AI</h2><div class=description-block>Robotics and IoT systems involve processing of sensor data in order to perform analysis of events that lead to better decisions either by humans or autonomous agents such as mobile robots. We mainly work on real-time object detection with cameras/lidars as well as processing of other sensor data such as Inertial Motion Unit (IMU)</div><ul><li>Nordt, J., Ambegoda, T., & Chen, B. (2020). <a href=/assets/publications/cleaning-apparatus-and-method-for-operating-a-cleaning-apparatuspdf.pdf target=_blank>Cleaning apparatus and method for operating a cleaning apparatus</a>. US Patent App. 16/764,144.</li></ul><h2 id=document-analysis-and-digitization>Document Analysis and Digitization</h2><div class=description-block>Robotics and IoT systems involve processing of sensor data in order to perform analysis of events that lead to better decisions either by humans or autonomous agents such as mobile robots. We mainly work on real-time object detection with cameras/lidars as well as processing of other sensor data such as Inertial Motion Unit (IMU)</div><ul><li>Herath, D., Dinuwan, C., Ihalagedara, C., & Ambegoda, T. (2024). <a href=/assets/publications/enhancingeducationaloutcomesthroughaipoweredpdf.pdf target=_blank>Enhancing Educational Outcomes Through AI Powered Learning Strategy Recommendation System</a>. <em>International Journal of Advanced Computer Science & Applications</em>, 15(10).</li></ul><h2 id=computer-vision-and-machine-learning>Computer Vision and Machine Learning</h2><ul><li>Sivakumar, P., Janson, P., Rajasegaran, J., & Ambegoda, T. (2024). <a href=/assets/publications/fewshotnerf-meta-learning-based-novel-view-synthesis-for-rapid-scene-specific-adaptationpdf.pdf target=_blank>FewShotNeRF: Meta-Learning-based Novel View Synthesis for Rapid Scene-Specific Adaptation</a>. <em>arXiv preprint arXiv:2408.04803</em>.</li><li>Kanagarajah, S., Ambegoda, T., & Rodrigo, R. (2023). <a href=/assets/publications/sathur-self-augmenting-task-hallucinal-unified-representation-for-generalized-class-incremental-learningpdf.pdf target=_blank>SATHUR: Self Augmenting Task Hallucinal Unified Representation for Generalized Class Incremental Learning</a>. In <em>Proceedings of the IEEE/CVF International Conference on Computer Vision</em> (pp. 3473-3480).</li><li>Ambegoda, T. D., & Cook, M. (2020). <a href=/assets/publications/efficient-2d-neuron-boundary-segmentation-with-local-topological-constraintspdf.pdf target=_blank>Efficient 2D neuron boundary segmentation with local topological constraints</a>. <em>arXiv preprint arXiv:2002.01036</em>.</li><li>Ambegoda, T. D., Martel, J. N. P., Adamcik, J., Cook, M., & Hahnloser, R. H. R. (2020). <a href=/assets/publications/estimation-of-z-thickness-and-xy-anisotropy-of-electron-microscopy-images-using-gaussian-processespdf.pdf target=_blank>Estimation of z-thickness and xy-anisotropy of electron microscopy images using gaussian processes</a>. <em>arXiv preprint arXiv:2002.00228</em>.</li></ul><h2 id=other-publications>Other Publications</h2><ul><li>Minoli, M., & Ambegoda, T. D. (2012). <a href=/assets/publications/knowledge-graphs-for-covid-19-a-survey-pdf.pdf target=_blank>Knowledge Graphs for COVID-19: A Survey</a>. In <em>Advanced AI and Internet of Health Things for Combating Pandemics</em> (pp. 3-19). Springer.</li><li>Ambegoda Liyana Arachchige, T. D. (2017). <a href=/assets/publications/em-image-analysis-for-neuron-segmentation-thickness-estimation-and-synaptic-bouton-quantificationpdf.pdf target=_blank>EM image analysis for neuron segmentation, thickness estimation, and synaptic bouton quantification</a>. <em>PhD Thesis, ETH Zurich</em>.</li><li>Ambegoda, A. L. A. T. D., De Silva, W. T. S., Hemachandra, K. T., Samarasinghe, T. N., & Samarasinghe, A. T. L. K. (2008). <a href=/assets/publications/centralized-traffic-controlling-system-for-sri-lanka-railwayspdf.pdf target=_blank>Centralized traffic controlling system for Sri Lanka railways</a>. In <em>2008 4th International Conference on Information and Automation for Sustainability</em> (pp. 145-149). IEEE.</li></ul></div></div><hr class=footer-divider><footer class=footer><div class=container><div class="row justify-content-center"><div class=col-auto><p class="copyright text-muted text-center">Welcome to AITR ðŸ’™<br><span style=font-size:.8em>Last updated: June 14, 2025</span></p></div></div></div></footer></body></html>